# AI4Thai Crop Guardian - AI Services Deployment (Absolute Paths)
# This version uses absolute paths to prevent CI/CD path issues

version: '3.8'

services:
  # Vision Service - Pest Detection + Disease Detection (H100 16GB Optimized)
  vision-service:
    build:
      context: /builds/222-KPR/ai-thailand-hackathon-2025/ai-services/vision-service
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-h100-optimized}
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: team10-vision-service:${IMAGE_TAG:-latest}
    container_name: team10-vision-service
    ports:
      - "${VISION_SERVICE_PORT:-2001}:2001"
    environment:
      # Model Configuration - H100 16GB Optimized
      - MODEL_CACHE_DIR=/app/models
      - HUGGINGFACE_HUB_CACHE=/app/models/hub
      - TRANSFORMERS_CACHE=/app/models/transformers

      # HuggingFace Configuration
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN}
      - HF_HOME=/app/models

      # Service Configuration
      - SERVICE_HOST=0.0.0.0
      - SERVICE_PORT=2001
      - MAX_WORKERS=1
      - WORKER_TIMEOUT=300

      # Model Settings - Memory Optimized
      - PEST_DETECTION_MODEL=underdogquality/yolo11s-pest-detection
      - DISEASE_DETECTION_MODEL=YuchengShi/LLaVA-v1.5-7B-Plant-Leaf-Diseases-Detection
      - CONFIDENCE_THRESHOLD=0.01
      - MAX_IMAGE_SIZE=5242880  # Reduced to 5MB for memory efficiency
      - MAX_BATCH_SIZE=1

      # H100 16GB GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - TORCH_CUDA_ARCH_LIST="9.0"
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2048,expandable_segments:True
      - CUDA_LAUNCH_BLOCKING=0
      - TORCH_CUDNN_V8_API_ENABLED=1

      # Memory Optimization for 16GB VRAM
      - MODEL_MAX_LENGTH=512
      - GRADIENT_CHECKPOINTING=true
      - USE_FLASH_ATTENTION=true
      - TORCH_COMPILE=false  # Disable for stability

      # Performance - Conservative for Memory
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1

      # Redis for caching
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}

      # Monitoring
      - ENABLE_METRICS=true
      - METRICS_PORT=9001
    volumes:
      - team10-root:/root
      - team10-data:/app/models
    networks:
      - ai-services-network
    deploy:
      resources:
        limits:
          memory: ${VISION_MEMORY_LIMIT:-4G}  # Aggressive reduction for memory optimization
        reservations:
          memory: ${VISION_MEMORY_RESERVATION:-2G}  # Minimal reservation
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2001/health"]
      interval: 30s
      timeout: 15s
      retries: 2  # Reduced retries
      start_period: 60s  # Reduced startup time
    restart: unless-stopped

  # Queue Worker Service - Vision Job Processing
  queue-worker:
    build:
      context: /builds/222-KPR/ai-thailand-hackathon-2025/ai-services/queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: team10-queue-worker:${IMAGE_TAG:-latest}
    container_name: team10-queue-worker
    ports:
      - "${QUEUE_WORKER_PORT:-2003}:2003"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - VISION_SERVICE_URL=http://vision-service:2001
      - MAX_IMAGE_SIZE=10485760  # 10MB
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - QUEUE_PORT=2003
    depends_on:
      - redis
      - vision-service
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2003/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # Celery Worker - Background Processing
  celery-worker:
    build:
      context: /builds/222-KPR/ai-thailand-hackathon-2025/ai-services/queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: team10-queue-worker:${IMAGE_TAG:-latest}
    container_name: team10-celery-worker
    command: celery -A tasks worker --loglevel=info --concurrency=2
    environment:
      - REDIS_URL=redis://redis:6379/0
      - VISION_SERVICE_URL=http://vision-service:2001
      - MAX_IMAGE_SIZE=10485760
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
      - vision-service
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    deploy:
      resources:
        limits:
          memory: 2G  # Reduced for queue worker
        reservations:
          memory: 512M  # Minimal for queue processing
    restart: unless-stopped

  # Celery Beat - Scheduled Tasks
  celery-beat:
    build:
      context: /builds/222-KPR/ai-thailand-hackathon-2025/ai-services/queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: team10-queue-worker:${IMAGE_TAG:-latest}
    container_name: team10-celery-beat
    command: celery -A tasks beat --loglevel=info
    environment:
      - REDIS_URL=redis://redis:6379/0
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    restart: unless-stopped

  # Redis - Cache, Session Management, and Job Queue
  redis:
    image: redis:7-alpine
    container_name: team10-ai-redis
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - team10-root:/root
      - team10-data:/data
    networks:
      - ai-services-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

networks:
  ai-services-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  team10-root:
    driver: local
  team10-data:
    driver: local
