# AI4Thai Crop Guardian - AI Services Deployment  
# Vision Service and Queue Worker for agricultural analysis

version: '3.8'

services:
  # Vision Service - Pest Detection + Disease Detection
  vision-service:
    build:
      context: ../vision-service
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
    container_name: team10-vision-service
    ports:
      - "${VISION_SERVICE_PORT:-2001}:2001"
    environment:
      # Model Configuration
      - MODEL_CACHE_DIR=/app/models
      - HUGGINGFACE_HUB_CACHE=/app/models/hub
      - TRANSFORMERS_CACHE=/app/models/transformers
      
      # HuggingFace Configuration
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN}
      - HF_HOME=/app/models
      
      # Service Configuration
      - SERVICE_HOST=0.0.0.0
      - SERVICE_PORT=2001
      - MAX_WORKERS=1
      - WORKER_TIMEOUT=300  # Extended for LLaVA model
      
      # Model Settings
      - PEST_DETECTION_MODEL=underdogquality/yolo11s-pest-detection
      - DISEASE_DETECTION_MODEL=YuchengShi/LLaVA-v1.5-7B-Plant-Leaf-Diseases-Detection
      - CONFIDENCE_THRESHOLD=0.01
      - MAX_IMAGE_SIZE=10485760  # 10MB
      
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6"
      
      # Performance
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      
      # Redis for caching
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      
      # Monitoring
      - ENABLE_METRICS=true
      - METRICS_PORT=9001
    volumes:
      - team10-root:/root
      - team10-data:/app/models
    networks:
      - ai-services-network
    deploy:
      resources:
        limits:
          memory: ${VISION_MEMORY_LIMIT:-12G}  # Increased for dual models
        reservations:
          memory: ${VISION_MEMORY_RESERVATION:-6G}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2001/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s  # Extended for model loading
    restart: unless-stopped

  # Queue Worker Service - Vision Job Processing
  queue-worker:
    build:
      context: ../queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
    container_name: team10-queue-worker
    ports:
      - "${QUEUE_WORKER_PORT:-2003}:2003"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - VISION_SERVICE_URL=http://vision-service:2001
      - MAX_IMAGE_SIZE=10485760  # 10MB
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - QUEUE_PORT=2003
    depends_on:
      - redis
      - vision-service
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2003/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # Celery Worker - Background Processing
  celery-worker:
    build:
      context: ../queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
    container_name: team10-celery-worker
    command: celery -A tasks worker --loglevel=info --concurrency=2
    environment:
      - REDIS_URL=redis://redis:6379/0
      - VISION_SERVICE_URL=http://vision-service:2001
      - MAX_IMAGE_SIZE=10485760
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
      - vision-service
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 1G
    restart: unless-stopped

  # Celery Beat - Scheduled Tasks
  celery-beat:
    build:
      context: ../queue-worker
      dockerfile: Dockerfile
      target: ${BUILD_TARGET:-production}
    container_name: team10-celery-beat
    command: celery -A tasks beat --loglevel=info
    environment:
      - REDIS_URL=redis://redis:6379/0
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
    volumes:
      - team10-root:/root
      - team10-data:/app/data
    networks:
      - ai-services-network
    restart: unless-stopped

  # Redis - Cache, Session Management, and Job Queue
  redis:
    image: redis:7-alpine
    container_name: team10-ai-redis
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - team10-root:/root
      - team10-data:/data
    networks:
      - ai-services-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Load Balancer for Vision Service
  vision-lb:
    image: nginx:alpine
    container_name: team10-vision-lb
    ports:
      - "${VISION_LB_PORT:-2011}:80"
    volumes:
      - team10-root:/root
      - team10-data:/etc/nginx
    depends_on:
      - vision-service
    networks:
      - ai-services-network
    profiles:
      - load-balancer
    restart: unless-stopped

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: team10-ai-prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - team10-root:/root
      - team10-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-services-network
    profiles:
      - monitoring
    restart: unless-stopped

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: team10-ai-grafana
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - team10-root:/root
      - team10-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - ai-services-network
    profiles:
      - monitoring
    restart: unless-stopped

networks:
  ai-services-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  team10-root:
    driver: local
  team10-data:
    driver: local