# GitLab CI/CD Pipeline for AI4Thai Crop Guardian - AI Services Only
# Deploys AI services when tagged with 'hackathon-siamai2'

stages:
  - build
  - deploy

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  # AI Services Configuration
  VISION_SERVICE_PORT: "2001"
  QUEUE_WORKER_PORT: "2003"
  VISION_LB_PORT: "2011"
  REDIS_PORT: "6379"
  PROMETHEUS_PORT: "9090"
  GRAFANA_PORT: "3001"

# Build AI Services Images - Optimized for H100 16GB VRAM (No Artifacts)
build-ai-services:
  stage: build
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  before_script:
    - docker info
    - cd ai-services/deployment
    # Enable Docker BuildKit for optimized builds and size reduction
    - export DOCKER_BUILDKIT=1
    - export BUILDKIT_PROGRESS=plain
  script:
    # Build Vision Service with H100 optimization and size optimization
    - echo "Building Vision Service for H100 16GB VRAM (optimized size)..."
    - docker build --target h100-optimized --compress --squash -t team10-vision-service:$CI_COMMIT_SHA ../vision-service/
    - docker tag team10-vision-service:$CI_COMMIT_SHA team10-vision-service:latest

    # Build Queue Worker (optimized and minimal)
    - echo "Building Queue Worker (minimal)..."
    - docker build --target production --compress --squash -t team10-queue-worker:$CI_COMMIT_SHA ../queue-worker/
    - docker tag team10-queue-worker:$CI_COMMIT_SHA team10-queue-worker:latest

    # Optimize images by removing intermediate layers and unused data
    - docker image prune -f --filter="dangling=true"

    # Display final image sizes (for monitoring)
    - echo "Final Docker image sizes:"
    - docker images | grep team10

    # Verify images work
    - echo "Testing image functionality..."
    - docker run --rm team10-queue-worker:latest python -c "import fastapi; print('Queue Worker OK')"
    - docker run --rm team10-vision-service:latest python -c "import torch; print('Vision Service OK')"

    # No artifacts - images stay in local Docker daemon for deploy stage
    - echo "Build completed successfully - images ready for deployment"
  only:
    - tags
  except:
    - branches
  tags:
    - hackathon-siamai2

# Deploy AI Services
deploy-ai-services:
  stage: deploy
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  before_script:
    - apk add --no-cache docker-compose curl
    - docker info
    - cd ai-services/deployment
  script:
    # Rebuild images efficiently (fast due to layer caching)
    - echo "Building Docker images for deployment..."
    - export DOCKER_BUILDKIT=1

    # Build images with optimizations
    - docker build --target h100-optimized --compress -t team10-vision-service:latest ../vision-service/
    - docker build --target production --compress -t team10-queue-worker:latest ../queue-worker/

    # Verify images are built
    - docker images | grep team10

    # Stop existing services if running
    - echo "Stopping existing AI services..."
    - docker-compose down --remove-orphans || true

    # Clean up old containers and volumes (optional)
    - docker container prune -f || true

    # Set environment variables for H100 16GB deployment
    - export VISION_SERVICE_PORT=$VISION_SERVICE_PORT
    - export QUEUE_WORKER_PORT=$QUEUE_WORKER_PORT
    - export VISION_LB_PORT=$VISION_LB_PORT
    - export REDIS_PORT=$REDIS_PORT
    - export PROMETHEUS_PORT=$PROMETHEUS_PORT
    - export GRAFANA_PORT=$GRAFANA_PORT
    - export BUILD_TARGET=h100-optimized
    - export VISION_MEMORY_LIMIT=4G
    - export VISION_MEMORY_RESERVATION=2G

    # Deploy AI services
    - echo "Deploying AI services..."
    - docker-compose up -d

    # Wait for services to be healthy
    - echo "Waiting for services to be ready..."
    - sleep 30

    # Health checks
    - echo "Performing health checks..."
    - curl -f http://localhost:$VISION_SERVICE_PORT/health || exit 1
    - curl -f http://localhost:$QUEUE_WORKER_PORT/health || exit 1

    # Display running containers
    - echo "AI Services deployment completed successfully!"
    - docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

    # Display volume usage
    - echo "Team10 volumes:"
    - docker volume ls | grep team10 || echo "No team10 volumes found"
  environment:
    name: production
    url: http://localhost:$VISION_SERVICE_PORT
  only:
    - tags
  except:
    - branches
  tags:
    - hackathon-siamai2
  when: manual
  # No dependencies needed since images are in Docker daemon

# Cleanup job (optional - runs on schedule or manual trigger)
cleanup-ai-services:
  stage: deploy
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  before_script:
    - apk add --no-cache docker-compose
    - cd ai-services/deployment
  script:
    - echo "Cleaning up AI services..."
    - docker-compose down --volumes --remove-orphans
    - docker system prune -f
    - docker volume prune -f
    - echo "Cleanup completed"
  only:
    - tags
  except:
    - branches
  tags:
    - hackathon-siamai2
  when: manual
  allow_failure: true

# Health check job (can be run independently)
health-check:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "Checking AI services health..."
    - curl -f http://localhost:$VISION_SERVICE_PORT/health
    - curl -f http://localhost:$QUEUE_WORKER_PORT/health
    - curl -f http://localhost:$VISION_LB_PORT/health || echo "Load balancer health check failed (may be expected)"
    - echo "All critical services are healthy!"
  only:
    - tags
  except:
    - branches
  tags:
    - hackathon-siamai2
  when: manual
  allow_failure: true
